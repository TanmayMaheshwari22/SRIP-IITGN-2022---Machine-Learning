{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworks using JAX.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question-3"
      ],
      "metadata": {
        "id": "2nKSgrdvgfho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p7ufmNdiuBIq"
      },
      "outputs": [],
      "source": [
        "#importing the required libraries.\n",
        "import numpy as np #importing numpy\n",
        "import jax.numpy as jnp #importing jax's numpy library so that all the functions of numpy can work in jax\n",
        "from jax.scipy.special import logsumexp #importing jax's function to sum log\n",
        "import jax #importing jax\n",
        "from jax import jit, vmap, pmap, grad, value_and_grad\n",
        "\n",
        "from torchvision.datasets import MNIST #importing  Pytorch so that MNIST data could be loaded\n",
        "from torch.utils.data import DataLoader #importing data loader to iterate through the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be building a model using MLP classifier\n",
        "# Our model will have two hidden layers and 1 input and ouput layer\n",
        "# Number of nodes in each layer will be 784,512,256,10"
      ],
      "metadata": {
        "id": "XzPej_BPksO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function below will help to initialise the parameters of our model"
      ],
      "metadata": {
        "id": "T8-3KL_CTZsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed = 0 #While using jax.random.PRNGKey we have to pass seed as an argument\n",
        "mnist_img_size = (28, 28)\n",
        "# It will use to generate all the parameters for the model i.e weights and biases\n",
        "# It takes data in the flatten form \n",
        "def params_MLP(layer_widths, parent_key, scale=0.01): #It takes argument as the number of neurons in each layer ,key for random number generation and scale to scale the data\n",
        "    # Generating all the parameters using jax.random function\n",
        "    params = []\n",
        "    keys = jax.random.split(parent_key, num=len(layer_widths)-1)\n",
        "\n",
        "    for in_width, out_width, key in zip(layer_widths[:-1], layer_widths[1:], keys):\n",
        "        weight_key, bias_key = jax.random.split(key)\n",
        "        params.append([\n",
        "                       scale*jax.random.normal(weight_key, shape=(out_width, in_width)),\n",
        "                       scale*jax.random.normal(bias_key, shape=(out_width,))\n",
        "                       ]\n",
        "        )\n",
        "\n",
        "    return params\n",
        "\n",
        "key = jax.random.PRNGKey(seed) # This function of JAX is used to create random numbers by producing keys.\n",
        "MLP_params = params_MLP([784, 512, 256, 10], key) # We will pass the number of nodes in each layer to the def init_MLP"
      ],
      "metadata": {
        "id": "2S-w-bEHuMm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e27e36c-c92a-4335-eb06-4e3e737a5e00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jax.tree_map(lambda x: x.shape, MLP_params)) # It is used to iterate through the pytree\n",
        "# In this case we are getting the shape of the weights and biases of each layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo9AVyWDe16N",
        "outputId": "f2ed101f-98ad-48c2-ffef-75a776d99d14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function below will help us to predict output given the input images and parameters as input"
      ],
      "metadata": {
        "id": "NeiOQdCEThVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This function helps in predicting the output\n",
        "#For hidden layers we will use relu function\n",
        "# This function will take paramters(weights and biases) and inputs(image in flattened form) as arguments\n",
        "def MLP_predict(params, x):\n",
        "    hidden_layers = params[:-1]\n",
        "\n",
        "    activation = x\n",
        "    for w, b in hidden_layers:\n",
        "        activation = jax.nn.relu(jnp.dot(w, activation) + b) #applying relu function \n",
        "    # Deaking last layer separately as we can't apply relu on it.\n",
        "    w_last, b_last = params[-1]\n",
        "    logits = jnp.dot(w_last, activation) + b_last\n",
        "\n",
        "    # log(exp(o1)) - log(sum(exp(o1), exp(o2), ..., exp(o10)))\n",
        "    # log( exp(o1) / sum(...) )\n",
        "    return logits - logsumexp(logits) # it can be considered as softmax function with log.\n",
        "\n",
        "# tests\n",
        "\n",
        "# test single example\n",
        "\n",
        "dummy_img_flat = np.random.randn(np.prod(mnist_img_size))\n",
        "print(dummy_img_flat.shape)\n",
        "\n",
        "prediction = MLP_predict(MLP_params, dummy_img_flat)\n",
        "print(prediction.shape)\n",
        "\n",
        "# test batched function\n",
        "batched_MLP_predict = vmap(MLP_predict, in_axes=(None, 0)) #vmap vectorise our functions\n",
        "\n",
        "dummy_imgs_flat = np.random.randn(16, np.prod(mnist_img_size)) # taking 16 images for example\n",
        "print(dummy_imgs_flat.shape)\n",
        "predictions = batched_MLP_predict(MLP_params, dummy_imgs_flat)\n",
        "print(predictions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiHEb2ITsNlV",
        "outputId": "d73644d0-2f1a-414f-91c8-783154652239"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784,)\n",
            "(10,)\n",
            "(16, 784)\n",
            "(16, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function below will help us to load MNIST data from pytorch and converting it into the required form in which our model takes input i.e it take input in flatten form"
      ],
      "metadata": {
        "id": "mjeXGvvBTpxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will be used to flatten the images into 1-D form\n",
        "def custom_transform(x):\n",
        "     return np.ravel(np.array(x, dtype=np.float32))\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "      transposed_data = list(zip(*batch))\n",
        "\n",
        "      labels = np.array(transposed_data[1])\n",
        "      imgs = np.stack(transposed_data[0])\n",
        "\n",
        "      return imgs, labels\n",
        "\n",
        "batch_size = 128\n",
        "train_dataset = MNIST(root='train_mnist', train=True, download=True, transform=custom_transform) #loading the training data\n",
        "test_dataset = MNIST(root='test_mnist', train=False, download=True, transform=custom_transform) #loading the testing data\n",
        "\n",
        "#Data Loader will be used to iterate between the input and the output label\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True) # Using Data loader to iterate thorugh training data \n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True) # Iterating through test data\n",
        "\n",
        "# # test\n",
        "# batch_data = next(iter(train_loader))\n",
        "# imgs = batch_data[0]\n",
        "# lbls = batch_data[1]\n",
        "# print(imgs.shape, imgs[0].dtype, lbls.shape, lbls[0].dtype)\n",
        "\n",
        "# optimization - loading the whole dataset into memory\n",
        "train_images = jnp.array(train_dataset.data).reshape(len(train_dataset), -1) # Laoding and Reshaping the training input into the required form\n",
        "train_lbls = jnp.array(train_dataset.targets) # Getting the labels\n",
        "\n",
        "#Similarly for test data\n",
        "test_images = jnp.array(test_dataset.data).reshape(len(test_dataset), -1)\n",
        "test_lbls = jnp.array(test_dataset.targets)\n"
      ],
      "metadata": {
        "id": "N6wWg7xTt8OW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to create the loss function,accuracy function and gradient descent function"
      ],
      "metadata": {
        "id": "3zmUa4lzYZXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5 #No. of epochs i.e number of times we want to run our code\n",
        "\n",
        "def loss_fn(params, imgs, gt_lbls): # This function will return the probability of each class and class with the maximum prob will be our answer.\n",
        "    predictions = batched_MLP_predict(params, imgs)\n",
        "\n",
        "    return -jnp.mean(predictions * gt_lbls)\n",
        "\n",
        "def accuracy(params, dataset_imgs, dataset_lbls): #This function returns accuracy of our model\n",
        "    pred_classes = jnp.argmax(batched_MLP_predict(params, dataset_imgs), axis=1)\n",
        "    return jnp.mean(dataset_lbls == pred_classes) \n",
        "\n",
        "@jit #This function is used for gradient descent\n",
        "def update(params, imgs, gt_lbls, lr=0.01):\n",
        "    loss, grads = value_and_grad(loss_fn)(params, imgs, gt_lbls)\n",
        "\n",
        "    return loss, jax.tree_multimap(lambda p, g: p - lr*g, params, grads) \n",
        "\n",
        "# Create a MLP\n",
        "# Calculating the accuracy of our model\n",
        "MLP_params = params_MLP([np.prod(mnist_img_size), 512, 256, len(MNIST.classes)], key) #Using params_MLP function to initialise weights and biases\n",
        "loss_array_per_epoch=[] #This will store the loss after each epoch\n",
        "loss_array=[] # This will store the mean of loss of each epoch\n",
        "# Running loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for cnt, (imgs, lbls) in enumerate(train_loader):\n",
        "\n",
        "        gt_labels = jax.nn.one_hot(lbls, len(MNIST.classes)) # This function will convert our output into one hot encoded form\n",
        "        \n",
        "        loss, MLP_params = update(MLP_params, imgs, gt_labels)\n",
        "        \n",
        "        if cnt % 50 == 0:\n",
        "          loss_array_per_epoch.append(loss)\n",
        "          print(loss)\n",
        "    loss_array.append(np.mean(loss_array_per_epoch))\n",
        "    print(f'Epoch {epoch}, train acc = {accuracy(MLP_params, train_images, train_lbls)} ,test acc = {accuracy(MLP_params, test_images, test_lbls)}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meZney6Z4h_W",
        "outputId": "f2e63e24-7ee0-453b-d2ce-9bd01c219a8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24367991\n",
            "0.092278086\n",
            "0.05395074\n",
            "0.05768485\n",
            "0.03936691\n",
            "0.03720045\n",
            "0.02969088\n",
            "0.035295505\n",
            "0.038697656\n",
            "0.020503357\n",
            "Epoch 0, train acc = 0.9146666526794434 ,test acc = 0.9158999919891357\n",
            "0.03332108\n",
            "0.034529954\n",
            "0.01722318\n",
            "0.02683354\n",
            "0.015945788\n",
            "0.024562618\n",
            "0.026031425\n",
            "0.031669255\n",
            "0.018338528\n",
            "0.015763743\n",
            "Epoch 1, train acc = 0.9349499940872192 ,test acc = 0.9354999661445618\n",
            "0.035945144\n",
            "0.028820265\n",
            "0.016952774\n",
            "0.018214969\n",
            "0.022933586\n",
            "0.028821474\n",
            "0.025626162\n",
            "0.01691821\n",
            "0.022955025\n",
            "0.02523438\n",
            "Epoch 2, train acc = 0.9467333555221558 ,test acc = 0.9441999793052673\n",
            "0.013056374\n",
            "0.019024184\n",
            "0.015239847\n",
            "0.012443261\n",
            "0.008114476\n",
            "0.021228526\n",
            "0.016153788\n",
            "0.016005633\n",
            "0.018906185\n",
            "0.01871697\n",
            "Epoch 3, train acc = 0.9541833400726318 ,test acc = 0.9508999586105347\n",
            "0.01836065\n",
            "0.018456703\n",
            "0.016245583\n",
            "0.017011894\n",
            "0.020449666\n",
            "0.015836267\n",
            "0.013143979\n",
            "0.017304976\n",
            "0.020653365\n",
            "0.0051454348\n",
            "Epoch 4, train acc = 0.9607499837875366 ,test acc = 0.9536999464035034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of the training data =0.9607499837875366\n",
        "\n",
        "Accuracy of the testing data= 0.9536999464035034"
      ],
      "metadata": {
        "id": "604qRjGPbfES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZcK_J2-PKER",
        "outputId": "0757f9a5-52ef-4f0f-92a0-21cdf94ba26e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06483483, 0.044628374, 0.03783298, 0.032346968, 0.029129744]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt #Importing matplotlib to draw graph between loss and no. of epochs"
      ],
      "metadata": {
        "id": "WYbKsVL6TOap"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph between loss and no. of epochs\n",
        "plt.plot(np.arange(num_epochs),loss_array)\n",
        "plt.xlabel('No. of epochs')\n",
        "plt.ylabel('Loss per epochs')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.show()\n",
        "#We can see that as the number epochs increases the value of loss function decreases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "C3hObk6cTRv3",
        "outputId": "b34807c6-25fa-49c2-fc4d-8fea19dfd2c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}